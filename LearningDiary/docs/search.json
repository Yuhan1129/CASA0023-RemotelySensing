[
  {
    "objectID": "Week1.html#summary",
    "href": "Week1.html#summary",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 Remote Sensors\nA remote sensor system it the instrument designed to detect and measure physical phenomena or environmental conditions from a distance. Remote sensors could be divided into two types as follow:\n\nPassive sensors systems: receive reflected energy\nActive sensors systems: emit electromagnetic waves, such as SAR\n\n\n\n1.1.2 Electromagnetic waves\nThe electromagnetic waves are used by remote sensors to detect and measure physical phenomena, also the carriers of information.\nThe basic properties of electromagnetic waves include wave length(\\(\\lambda\\)), velocity( \\(c\\), rate of oscillation), frequency(\\(v = 3\\times10^8 m/s\\)). They follow the relationship that \\(\\lambda = c/v\\).\n\nRelated jargon\nThere are also some jargon about electromagnetic waves we need to know:\n\nElectromagnetic radiation(EMR): waves of an electromagnetic field, travel through space and carry radiant\nradiant energy: energy carried by EMR waves\nradiant flux: energy per unit of time\nshortwave radiation: energy from the sun\nsolar irradiacne: energy or solar power from the sun per unit area per unit time\nexitance/emmittance: energy leaving a surface per unit per unit time\n\n\n\n1.1.2.1 Interactions with Earth\nWhen the electromagnetic waves travel to reach the ground stations or remote sensors, they would be affected by Earth’s atmosphere or surface.Thus, it’s important to know how would the Earth’s surface or atmosphere would change the radiant energy.\n\n1.1.2.1.1 Interactions with Earth’s atmosphere\nSome of the particles or molecules in the air would absorb part of electromagnetic waves, while others would change the direction of electromagnetic waves, and this phenomenon is called atmospheric scattering.\nThere are three types of atmospheric scattering:\n\nRayleigh scattering:\nIt happens when particles are very small compared to the wavelength.\nSmaller wavelengths scatter easier, like blue light would scatter more than red light and yellow light. That’s why we would the sky is blue in the daytime, and the sun is yellow and red when sunset as the sun’s angle changes and the light should travel through more Earth’s atmosphere so that more blue light is scattered out.\nMie scattering:\nIt happens when the particles’ diameters are equal to the wavelength.\nNon selective scattering:\nIt happens when the particles are much larger than the wavelength. For example, the clouds would scatter the visible light of the solar radiation. And that’s the reason why we could see the clouds are white in remote sensing images.\n\n\n\n1.1.2.1.2 Interactions with Earth’s surface\nAfter the solar radiation reached the Earth surface, it would either be absorbed, transmitted or reflected. As for remote sensing, the reflected electromagnetic waves could tell use the characteristics of the Earth’s surface.\nSeveral types of surface interactions: Bidirectional Reflectance Distribution Function (BRDF), Polarization, Fluorensence\n\n\n\n\n1.1.3 Remote Sensing Data\n\n1.1.3.1 Data formats\nMostly remote sensing data is stored in raster, and the file formats usually include GeoTiff and HDF, etc.\n\n\n1.1.3.2 Four resolutions\nRemote sensing data are based on four resolutions\n\nSpatial Resolution: The size of the raster cells.\nSpectral Resolution: The number of bands it records data in.\nThere are several concepts related to spectral resolution:\n\nspectral signatures:\nWe take values for each wavelength across the electromagnetic spectrum to create a spectral signature. Every feature on earth have a unique spectral signature\natmospheric window:\nThe observable wavelengths ranges that are not absorbed by the atmosphere and are transmitted through the atmosphere. Water vapour, ozone, carbon dioxide and atmospheric molecules blocks 100% of the gamma rays, x-rays, and most ultra-violet light.\n\n\n\nFigure 1. Atmospheric Window\n\n\n\nRadiometric Resolution: The ability of a sensor to identify and shows small differences.\nTemporal Resolution: The revisit time of the sensor."
  },
  {
    "objectID": "Week1.html#application",
    "href": "Week1.html#application",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nWe have already known that each object on the Earth has their own spectral signature, and it is also real that the same object in different status would have different spectral signatures, like healthy tree would show different colors compared to pest-infested trees. Meanwhile, forest are facing multiple threats and stressors, including deforestation, climate changes, invasive speicies and etc.(Lausch et al. 2016; Lewis, Edwards, and Galbraith 2015) In this way, one important application of spectral indicators is forest monitoring.\nGupta and Pandey (2021) developed a systematic approach using Sentinel-2A spectral images to measure the forest health. The workflow could be seen as below.\n\nIn terms of data collection and preprocessing, Gupta and Pandey (2021) collected Sentinel 2A data in May and October 2019, and resampled the data into 30m, then performed atmospheric correction. At the same time, they convert the digital numbers of top-of-atmosphere reflectance into bottom-of-atmosphere, which is the true surface reflectance.\nThen, they used reflectance estimation to calculate ARI 1, which shows signs of stressed related to pigments. They applied the Near Infrared(NIR) band to calculating the NDVI so that greenness vegetation are measured. The structure insensitive pigment index were also calculated. These three index were all calculated from spectral bands(see as Figure 3 below). Canopy chlorophyll content is based on the inversion of PROSAIL.\n\nFinally, all the four index combined together to calculate the comprehensive Forest Health index. As we can see the figure below, different colors show various health conditions of the forest. The reddest area shows that the forests of this area are in poorest health, while the greenest area’s forests are the healthiest. And we could conclude that the forest in October is healthier than forest in May. And the authors interpolate that the temperature and precipitation are strong drivers of tree growth and mortality.\n\nHowever, what presented above is just one application in forest health monitoring, there has been a lot of other research focusing on different forest spectral indices according to different spatial and temporal scales(Lechner, Foody, and Boyd 2020). For instance, while UAV data can capture millimeter-scale spatial-resolution data, the resulting remote-sensing images may contain tree branches, ground cover through gaps in the canopies, individual leaves at different angles, and shadows. But for many classification algorithm, it is better to not differentiate between individual elements of a tree.\n\n\n\nFigure 5. Spatial and temporal scales of ecological phenomenon"
  },
  {
    "objectID": "Week1.html#reflection",
    "href": "Week1.html#reflection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n\nThe remote sensing has a wide variety of applications, ranging from the particle matters in the atmosphere to the mineral detection beneath the earth surfaces. It has revolutionized our ability to study and monitor our planet, as it allows us to collect data on a scale and level of detail that was previously impossible. Just by receiving or transmitting electromagnetic waves, the remote sensors could decipher so much information so that we could observe the earth from a distance.\nIn the practical, we have used QGIS, SNAP and R for processing different satellite images. To be honest, if not required for using SNAP for a try, I would never open this software anymore. It is cumbersome to use and its GUI is quite old-fashion. Whereas, they all take a long time to process images. Just looking forward to seeing how powerful and fast GEE is.\n\n\n\n\n\nGupta, Saurabh Kumar, and Arvind Chandra Pandey. 2021. “Spectral Aspects for Monitoring Forest Health in Extreme Season Using Multispectral Imagery.” The Egyptian Journal of Remote Sensing and Space Science 24 (3, Part 2): 579–86. https://doi.org/10.1016/j.ejrs.2021.07.001.\n\n\nLausch, Angela, Stefan Erasmi, Douglas J. King, Paul Magdon, and Marco Heurich. 2016. “Understanding Forest Health with Remote Sensing -Part IA Review of Spectral Traits, Processes and Remote-Sensing Characteristics.” Remote Sensing 8 (12): 1029. https://doi.org/10.3390/rs8121029.\n\n\nLechner, Alex M., Giles M. Foody, and Doreen S. Boyd. 2020. “Applications in Remote Sensing to Forest Ecology and Management.” One Earth 2 (5): 405–12. https://doi.org/10.1016/j.oneear.2020.05.001.\n\n\nLewis, Simon L., David P. Edwards, and David Galbraith. 2015. “Increasing Human Dominance of Tropical Forests.” Science 349 (6250): 827–32. https://doi.org/10.1126/science.aaa9932."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Week4-policy.html",
    "href": "Week4-policy.html",
    "title": "4  Policy",
    "section": "",
    "text": "5 Summary\nThe combination of spectral bands\nMany cities have published policies for city sustainable development, however,\n\n\n6 Application\n\n\n7 Reflection"
  },
  {
    "objectID": "Week3-corrections.html#summary",
    "href": "Week3-corrections.html#summary",
    "title": "3  Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Correction\n\n3.1.1.1 Geometric Correction\nCauses: view angle(off-nadir, off directly down), topography, wind, rotation of the earth\nSolution:\n\nSteps:\n\n\nFind Ground Control Points(GCP) to match known points in the incorrect image and a reference correct dataset.\nThen use a transformation algorithm to model the actual coordinates, like linear regression with distorted x or y as the dependent or independent.\nLater, plot these and minimize the RMSE, whereas the lower RMSE the better model fits.\nLast, resample the final raster because the value of pixels in raster might shift slightly, and the common resample data including Nearest Neighbor, Linear, Cubic and Cubic Spline.\n\n\nTwo Methods:\n\nForward Mapping: Input to output\nThere would be points in the incorrect map falling outside the boundary of the correct map.\nBackward Mapping: Output to input\nThis method completely avoids problems with gaps and overlaps.\n\n\n3.1.1.2 Atmospheric Correction\nCauses: atmospheric scattering and topographic attenuation\nTips: There are both necessary and unnecessary atmospheric corrections. We only need to do the necessary atmospheric corrections.\nSolutions:\n\nTypes:\n\n\nRelative correction: Avoid the evaluation of atmospheric components of any kind(“Living Textbook | Relative Atmospheric Correction | by ITC, University of Twente,” n.d.).\n\nNormalize intensities of different bands within a single image\nNormalize intensities of bands from many dates to one date\nDark object subtraction or histogram adjustment\nPseudo-invariant Features(PIFS)\n\nAbsolute correction:\n\nRequirements: an atmospheric model, local atmospheric visibility and image altitude\nChange digital brightness values into scaled surface reflectance\n\nEmpirical line correction\nSteps:\n\nUsing a filed spectrometer,which require measurements at the same time as the satellite overpass\nThen use this measurements in linear regression against the satellite data raw digital number.\n\n\n\n\n3.1.1.3 Orthorectification Correction\nCauses: a systematic sensor and platform-induced geometry errors, which introduce terrain distortions when the sensor is not pointing directly at the Nadir location of the sensor.\nSolution:\n\nCosine correction\nMinnaert correction\nStatistical Empirical correction\nC Correction (advancing the Cosine)\n\n\n\n3.1.1.4 Radiometric Calibration\nCauses: sensors capture images brightness and distributed as a Digital Number(DN), which allows for efficient storage but has no units.\nSolution:\nDN to spectral radiance\n\n\n\n3.1.2 Data Joining and Enhancement\n\n3.1.2.1 Data Joining\nMosaicking:\n\nseamless image: the final image, images feathered together\nseamline: the dividing line between the base image and ‘other’ or second image\nfeathering: give similar brightness values of the two images.\n\n\n\n3.1.2.2 Image Enhancement\nContrast enhancement: Images usually do not have good contrast. The methods: min-max, percentage linear and standard deviation, piecewise linear contrast stretch\nOther enhancements:\n\nRatio\nFiltering\n\nLow pass or low frequency (averages the surrounding pixels)\nHigh pass or high frequency - enhance local variations\n\nPCA(Principal Component Analysis): Transform multi-spectral data into uncorrelated and smaller dataset, and reduce future computation\nTexture: Spatial variation of gray values\nfusion: Fusing data from multiple sensors / sources together"
  },
  {
    "objectID": "Week3-corrections.html#application",
    "href": "Week3-corrections.html#application",
    "title": "3  Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\nAs the influx of earth observation data enable us to closely monitor the environmental status at various scales(Pekel et al. 2016), the usage complexity and volume of data would be easily overwhelming(Frantz 2019). Therefore, the earth observation data are in urgent to be pre-processed for immediate analysis, which is\n\nAnalysis Ready Data\nmostly used to describe radiometrically and geometrically consistent data that include cloud and other poor-quality observation flags for filtering data prior to analysis(Dwyer et al. 2018)\n\nHowever, when the ARD dataset was still not common to us all, we still needed to do corrections with remote sensing images. Otherwise, there would be significant impacts on our research. And below are the applications and operations of corrections in research.\nIn Hadjimitsis et al. (2010)’s work, to evaluate the impacts of atmospheric correction on the agricultural application(detailly, the calculation of vegetation indices), they finished the geometric correction, radiometric correction at Yeroskipou area in Paphos district (the south-west area of Cyprus).\nFirstly, the images were geometrically corrected and geo-referenced to the World Geodetic System’84 (WGS 84/UTM) projection system using a suitable number of identifiable ground control points. Then they used a second order polynomial transformation and kept the RMSE smaller than 1 pixel.\nAs for radiometric correction, as usual, they converted Digital Numbers(DN) to units of radiance by using standard calibration values. Then, the darkest pixel atmospheric correction method (also termed as histogram minimum method) was applied. To calibrate the at-satellite radiance values in each spectral band for the study area, a dark target (e.g. a water dam) was carefully chosen. The average radiance value of the dark target was then subtracted from each at-satellite radiance value in every spectral band.\nFinally, they tested the impact of atmospheric effects on (a) the calculation of vegetation indices; (b) comparison between at-satellite reﬂectance and spectro-radiometric values; and (c) the calculation of real daily evapotranspiration.\nTen Landsat TM/ETM+ images were utilized to assess the impact of atmospheric correction on the accuracy of vegetation indices and evapotranspiration estimates. The results indicate that atmospheric effects must be taken into account for the calculation of DVI, NDVI, SAVI, and MSAVI indices.\nEven the availability of ARD improve the efficiency for research, some processing is still necessary. It is stated that the variability in data availability across space and time, along with partial incompleteness caused by clouds, acquisition orbits, and observation scenarios, necessitates the use of specialized algorithms or an additional round of processing. This is required to generate spatial completeness and temporal equidistance, ensuring that the data is ready for analysis(Frantz 2019). Therefore, it is cruicial to have highly analysis ready data(hARD) and hARD+, see as figure below.\n\n\n\nFigure1. Framework for Operational Radiometric Correct for Environmental Monitoring"
  },
  {
    "objectID": "Week3-corrections.html#reflection",
    "href": "Week3-corrections.html#reflection",
    "title": "3  Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\n\n\n\n\n\n\n\nDwyer, John L., David P. Roy, Brian Sauer, Calli B. Jenkerson, Hankui K. Zhang, and Leo Lymburner. 2018. “Analysis Ready Data: Enabling Analysis of the Landsat Archive.” Remote Sensing 10 (9): 1363. https://doi.org/10.3390/rs10091363.\n\n\nFrantz, David. 2019. “FORCELandsat + Sentinel-2 Analysis Ready Data and Beyond.” Remote Sensing 11 (9): 1124. https://doi.org/10.3390/rs11091124.\n\n\nHadjimitsis, D. G., G. Papadavid, A. Agapiou, K. Themistocleous, M. G. Hadjimitsis, A. Retalis, S. Michaelides, N. Chrysoulakis, L. Toulios, and C. R. I. Clayton. 2010. “Atmospheric Correction for Satellite Remotely Sensed Data Intended for Agricultural Applications: Impact on Vegetation Indices.” Natural Hazards and Earth System Sciences 10 (1): 89–95. https://doi.org/10.5194/nhess-10-89-2010.\n\n\n“Living Textbook | Relative Atmospheric Correction | by ITC, University of Twente.” n.d. https://ltb.itc.utwente.nl/498/concept/81688.\n\n\nPekel, Jean-François, Andrew Cottam, Noel Gorelick, and Alan S. Belward. 2016. “High-Resolution Mapping of Global Surface Water and Its Long-Term Changes.” Nature 540 (7633): 418–22. https://doi.org/10.1038/nature20584."
  },
  {
    "objectID": "Week2-portfolio.html",
    "href": "Week2-portfolio.html",
    "title": "2  Portfolio",
    "section": "",
    "text": "see as:\nhttps://yuhan1129.github.io/CASA0023-RemotelySensing/presentation/OLI.html"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "9  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Campbell, James B., and Randolph H. Wynne. 2011. Introduction to\nRemote Sensing, Fifth Edition. Guilford Press.\n\n\nChristian Ginzler. 2021. “Vegetation Height Model NFI.” https://doi.org/10.16904/1000001.1.\n\n\nDwyer, John L., David P. Roy, Brian Sauer, Calli B. Jenkerson, Hankui K.\nZhang, and Leo Lymburner. 2018. “Analysis Ready Data: Enabling\nAnalysis of the Landsat Archive.” Remote Sensing 10 (9):\n1363. https://doi.org/10.3390/rs10091363.\n\n\nEggimann, Sven. 2022. “Expanding Urban Green Space with\nSuperblocks.” Land Use Policy 117 (June): 106111. https://doi.org/10.1016/j.landusepol.2022.106111.\n\n\nFrantz, David. 2019. “FORCELandsat + Sentinel-2\nAnalysis Ready Data and Beyond.” Remote Sensing 11 (9):\n1124. https://doi.org/10.3390/rs11091124.\n\n\nFu, Yongyong, Kunkun Liu, Zhangquan Shen, Jinsong Deng, Muye Gan, Xinguo\nLiu, Dongming Lu, and Ke Wang. 2019. “Mapping Impervious Surfaces\nin TownRural Transition Belts Using China’s\nGF-2 Imagery and Object-Based Deep CNNs.” Remote Sensing\n11 (3): 280. https://doi.org/10.3390/rs11030280.\n\n\nGupta, Saurabh Kumar, and Arvind Chandra Pandey. 2021. “Spectral\nAspects for Monitoring Forest Health in Extreme Season Using\nMultispectral Imagery.” The Egyptian Journal of Remote\nSensing and Space Science 24 (3, Part 2): 579–86. https://doi.org/10.1016/j.ejrs.2021.07.001.\n\n\nHadjimitsis, D. G., G. Papadavid, A. Agapiou, K. Themistocleous, M. G.\nHadjimitsis, A. Retalis, S. Michaelides, N. Chrysoulakis, L. Toulios,\nand C. R. I. Clayton. 2010. “Atmospheric Correction for Satellite\nRemotely Sensed Data Intended for Agricultural Applications: Impact on\nVegetation Indices.” Natural Hazards and Earth System\nSciences 10 (1): 89–95. https://doi.org/10.5194/nhess-10-89-2010.\n\n\n“Historic Environment.” n.d. https://www.cityoflondon.gov.uk/services/planning/cityoflondon.gov.uk/services/planning/historic-environment.\n\n\nHolloway, Jacinta, and Kerrie Mengersen. 2018. “Statistical\nMachine Learning Methods and Remote Sensing for Sustainable Development\nGoals: A Review.” Remote Sensing 10 (9): 1365. https://doi.org/10.3390/rs10091365.\n\n\nHuang, C., L. S. Davis, and J. R. G. Townshend. 2002. “An\nAssessment of Support Vector Machines for Land Cover\nClassification.” International Journal of Remote Sensing\n23 (4): 725–49. https://doi.org/10.1080/01431160110040323.\n\n\nJovanović, Dušan, Milan Gavrilović, Dubravka Sladić, Aleksandra\nRadulović, and Miro Govedarica. 2021. “Building Change Detection\nMethod to Support Register of Identified Changes on Buildings.”\nRemote Sensing 13 (16): 3150. https://doi.org/10.3390/rs13163150.\n\n\nLausch, Angela, Stefan Erasmi, Douglas J. King, Paul Magdon, and Marco\nHeurich. 2016. “Understanding Forest Health with Remote Sensing\n-Part IA Review of Spectral Traits, Processes and\nRemote-Sensing Characteristics.” Remote Sensing 8 (12):\n1029. https://doi.org/10.3390/rs8121029.\n\n\nLawrence, Rick L., and Christopher J. Moran. 2015. “The\nAmericaView Classification Methods Accuracy Comparison Project: A\nRigorous Approach for Model Selection.” Remote Sensing of\nEnvironment 170 (December): 115–20. https://doi.org/10.1016/j.rse.2015.09.008.\n\n\nLechner, Alex M., Giles M. Foody, and Doreen S. Boyd. 2020.\n“Applications in Remote Sensing to Forest Ecology and\nManagement.” One Earth 2 (5): 405–12. https://doi.org/10.1016/j.oneear.2020.05.001.\n\n\nLewis, Simon L., David P. Edwards, and David Galbraith. 2015.\n“Increasing Human Dominance of Tropical Forests.”\nScience 349 (6250): 827–32. https://doi.org/10.1126/science.aaa9932.\n\n\nLi, Congcong, Jie Wang, Lei Wang, Luanyun Hu, and Peng Gong. 2014.\n“Comparison of Classification Algorithms and Training Sample Sizes\nin Urban Land Classification with Landsat Thematic Mapper\nImagery.” Remote Sensing 6 (2): 964–83. https://doi.org/10.3390/rs6020964.\n\n\n“Living Textbook | Relative Atmospheric Correction | by ITC,\nUniversity of Twente.” n.d. https://ltb.itc.utwente.nl/498/concept/81688.\n\n\nMaxwell, Aaron E., Timothy A. Warner, and Fang Fang. 2018.\n“Implementation of Machine-Learning Classification in Remote\nSensing: An Applied Review.” International Journal of Remote\nSensing 39 (9): 2784–2817. https://doi.org/10.1080/01431161.2018.1433343.\n\n\nNieuwenhuijsen, Mark J., and Haneen Khreis. 2016. “Car Free\nCities: Pathway to Healthy Urban Living.” Environment\nInternational 94 (September): 251–62. https://doi.org/10.1016/j.envint.2016.05.032.\n\n\nPekel, Jean-François, Andrew Cottam, Noel Gorelick, and Alan S. Belward.\n2016. “High-Resolution Mapping of Global Surface Water and Its\nLong-Term Changes.” Nature 540 (7633): 418–22. https://doi.org/10.1038/nature20584.\n\n\nSuel, Esra, John W. Polak, James E. Bennett, and Majid Ezzati. 2019.\n“Measuring Social, Environmental and Health Inequalities Using\nDeep Learning and Street Imagery.” Scientific Reports 9\n(1): 6229. https://doi.org/10.1038/s41598-019-42036-w.\n\n\nTamiminia, Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush,\nSarina Adeli, and Brian Brisco. 2020a. “Google Earth Engine for\nGeo-Big Data Applications: A Meta-Analysis and Systematic\nReview.” ISPRS Journal of Photogrammetry and Remote\nSensing 164 (June): 152–70. https://doi.org/10.1016/j.isprsjprs.2020.04.001.\n\n\n———. 2020b. “Google Earth Engine for Geo-Big Data Applications: A\nMeta-Analysis and Systematic Review.” ISPRS Journal of\nPhotogrammetry and Remote Sensing 164 (June): 152–70. https://doi.org/10.1016/j.isprsjprs.2020.04.001.\n\n\nTang, Zixia, Mengmeng Li, and Xiaoqin Wang. 2020. “Mapping Tea\nPlantations from VHR Images Using OBIA and Convolutional Neural\nNetworks.” Remote Sensing 12 (18): 2935. https://doi.org/10.3390/rs12182935.\n\n\nWang, Lei, Yang Chen, Luliang Tang, Rongshuang Fan, and Yunlong Yao.\n2018. “Object-Based Convolutional Neural Networks for Cloud and\nSnow Detection in High-Resolution Multispectral Imagers.”\nWater 10 (11): 1666. https://doi.org/10.3390/w10111666.\n\n\nXofis, Panteleimon, and Konstantinos Poirazidis. 2018. “Combining\nDifferent Spatio-Temporal Resolution Images to Depict Landscape Dynamics\nand Guide Wildlife Management.” Biological Conservation\n218 (February): 10–17. https://doi.org/10.1016/j.biocon.2017.12.003."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023-LearningDiary",
    "section": "",
    "text": "Preface\nWelcome to Learning Diary for CASA0023-Remotely Sensing"
  },
  {
    "objectID": "Week5-GEE.html",
    "href": "Week5-GEE.html",
    "title": "5  GEE",
    "section": "",
    "text": "6"
  },
  {
    "objectID": "Week5-GEE.html#summary",
    "href": "Week5-GEE.html#summary",
    "title": "5  GEE",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 What’s GEE?\n\nit uses Javascript, which is website programming language, variables are defined by var\nit allows massive datasets for quickly planetary scale analysis.\nin GEE, image refers to raster, feature refers to vector, ImageCollection refers to image stack, and FeatureCollection refers to feature stack(lots of polygons)\ncode runs on the client side, which is the browser, while the data is stored on the server side(ee)\n\n\n\n5.1.2 Why GEE?\n\nScale: The scale is set by the output instead of input.\n\nWhen doing analysis, GEE would aggregate the image to fit a 256*256 grid, and they would also select the pyramid with the closest scale and resample using nearest neighbor by default.\n\nProjection: This is what we don’t need to worry about in GEE. It converts all data into Mercator projection when displaying\n\n\n\n5.1.3 The Usages of GEE\n\n5.1.3.1 Building Blocks\n\nobjects: vector, raster, feature, string, number\n\neach belongs to a class\neach class has specific GEE functions/methods\n\ngeometry: point/line/(multi)polygon without attributes\nfeature: geometry with attributes\n\nfeature collection: multiple features with attributes\n\n\n\n\n5.1.3.2 Typical processes\n\ngeometry operations: joins, zonal statistics, filtering of images or specific values\nmethods: machine learning, supervised and unsupervised classification, etc.\napplications/outputs: online charts, scalable geospatial applications with GEE\nInstances:\n\nReducing images: reduce the collection to the extreme values for each pixel(collection.reduce(ee.Reducer()))\n\nBy region: most useful for zonal statistics(reduceRegion(), image.reduceRegions())\nBy neibourhood: a window of pixels surrounding a central pixel\n\nLinear regression: see the change over time in pixel values(linearFit())\nJoins: first put image collections or feature collections in a filter(ee.Filter), then join with join.apply()."
  },
  {
    "objectID": "Week5-GEE.html#application",
    "href": "Week5-GEE.html#application",
    "title": "5  GEE",
    "section": "5.2 Application",
    "text": "5.2 Application\nIn addition to a large repository of raw remotely sensed imagery, the GEE data catalog also offers preprocessed, mosaic images that have been processed to remove clouds. Table 1, as listed by Tamiminia et al. (2020a), provides a more comprehensive overview of the capabilities of packages in the GEE platform, I think, which would be enlightening for us to explore. Still, I believe that the most effective way of learning these things would be open the browser and look for the GEE APIs. And try to write your own code with interesting datasets.\n\nThey reviewed 349 papers used GEE in a wide variety of remote sensing applications, and categorized them into 11 different groups(shown in Figure below). Different values in the gear show the number of papers in related areas. It has shown that most studies are on crop mapping, including vegetation, rice paddy, and agricultural monitoring. This is followed by studies on water, land cover/land use, and disaster. The least number of studies are on data processing.\n\nIt is interesting to note that they also categorized all studies into two groups based on the type of data used: remote sensing data and ready-to-use products(such as NDVI and land cover). These two main categories were further subdivided into smaller categories(shown in Figure below) based on the methods. The most used methods are machine learning, while a small part of research focus on time-series analysis, feature extraction, image composite-visual interpretation and image pre-processing.\n\n\n\n\n\nIn machine learning, classification, clustering, regression and dimension deduction are four main algorithms(Holloway and Mengersen 2018). While in the papers Tamiminia et al. (2020b) investigated, they find that in GEE application classification and regression are the most popular machine learning algorithms in remote sensing. In detail, DT, CART, KNN, non-linear SVM, RF, and ANN are the most often-use non-parametric classification algorithms. In the category of others, time-series analysis, feature extraction, image composite-visual interpretation and image processing were applied to satellite images.\nEven GEE is powerful for geospatial and big data analysis, it has several limitations. Firstly, despite it has an extensive archive of satellite images, it has limited historical and high-resolution data. Notably, it could be challenging to implement new algorithms. For instance, Deep Learning has becoming extensively used in image classification. However, DL algorithms are not yet supported directly by GEE. The open-source framework like Tensorflow has been an important way of using DL in GEE."
  },
  {
    "objectID": "Week5-GEE.html#reflection",
    "href": "Week5-GEE.html#reflection",
    "title": "5  GEE",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\n\nAs shown in practical, GEE though powerful in computation, it becomes quite complex and verbose when doing some simple task like masking in R or QGIS. It seems that GEE is better suited for image analysis compared to vector-based processing.\n\n\n\n\n\n\nHolloway, Jacinta, and Kerrie Mengersen. 2018. “Statistical Machine Learning Methods and Remote Sensing for Sustainable Development Goals: A Review.” Remote Sensing 10 (9): 1365. https://doi.org/10.3390/rs10091365.\n\n\nTamiminia, Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush, Sarina Adeli, and Brian Brisco. 2020a. “Google Earth Engine for Geo-Big Data Applications: A Meta-Analysis and Systematic Review.” ISPRS Journal of Photogrammetry and Remote Sensing 164 (June): 152–70. https://doi.org/10.1016/j.isprsjprs.2020.04.001.\n\n\n———. 2020b. “Google Earth Engine for Geo-Big Data Applications: A Meta-Analysis and Systematic Review.” ISPRS Journal of Photogrammetry and Remote Sensing 164 (June): 152–70. https://doi.org/10.1016/j.isprsjprs.2020.04.001."
  },
  {
    "objectID": "Week4-policy.html#summary",
    "href": "Week4-policy.html#summary",
    "title": "4  Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 Heritage Conservation in London\nThe City of London is the ancient core from which the rest of London developed and is governed by the oldest local authority in the country(“Historic Environment,” n.d.). Its origins date back to before parliament and it has been an important center for settlement, commerce, and ceremony since Roman times. There are a high number of designated heritage assets in the City of London. It boasts a large number of designated heritage assets, including 600 listed buildings, 27 conservation areas, 48 scheduled ancient monuments, and four historic parks and gardens. Therefore, it is significant to conserve the heritage in London.\n\n\n4.1.2 Policy\nLocal\nThe London Plan\nIdentify important heritage and avoid/minimize harm on them.\n\nHC1.D Heritage Conservation and Growth\n\nDevelopment proposals should identify assets of archaeological significance and use this information to avoid harm or minimise it through design and appropriate mitigation.\n\n\nInternational\nUNESCO-World Heriatge Convention\nWorld Heritage sites must be preserved and improved to maintain their unique qualities and historical accuracy.\n\n3.1 Protection, conservation and management of World Heritage properties\n\nProtection and management of World Heritage properties should ensure that their Outstanding Universal Value, including the conditions of integrity and/or authenticity at the time of inscription, are sustained or enhanced over time.\n\n\n\n\n4.1.3 Activities\nLocal\nNorth Tottenham Townscape Heritage Initiative (THI)\n\n\nImprove the appearance of historic buildings with good quality design and encourage people to shop\nProvide opportunities for local people to learn about the heritage of Tottenham and become involved in its restoration and maintenance\nCreate an attractive environment that people can take pride in\n\n\nInternational\nThe World Heritage Cities Programme\n\n\nDevelop a theoretical framework for urban heritage conservation\nProvide technical assistance to States Parties for the implementation of new approaches and schemes\n\n\n\n\n4.1.4 Limitations\nWhile there are numerous policies governing heritage conservation and monitoring, there has yet to be a policy specifically addressing the identification, monitoring, and protection of heritage sites."
  },
  {
    "objectID": "Week4-policy.html#application",
    "href": "Week4-policy.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\n\n4.2.1 Discovering Heritage\nThanks to remote sensing, we could now identify surface features that may indicate the presence of hidden relics, as well as detect underground archaeological remains using infrared and thermal electromagnetic radiation.\nThe use of satellite imagery has been crucial in decreasing uncertainty regarding the condition of heritage assets(Tapete and Cigna 2018). For example, Orengo et al. (2020) used Sentinel-1 and Sentinel-2 data to detect archaeological mounds in Cholistan Desert area(Pakistan), known for its Bronze-Age Indus Civilization. They used a combination of SAR and optical bands to detect archaeological mounds from that era. Their research showed more mounds over a larger area than previously recorded and suggested a continuous shift of settlements due to changes in climate and hydrological networks throughout history.\n\n\n4.2.2 Monitoring And Conserving Heritage\nSatellite images can be used to monitor valuable heritage sites that are at risk of damage or destruction from climate change and natural hazards such as coastal erosion, urban sprawl, or land deformation.\nTzouvaras et al. (2019) used Sentinel-1 SAR images to map the effects of an earthquake on two UNESCO heritage sites in Cyprus: Nea Paphos and the “Tombs of the Kings”. By utilizing a Differential Synthetic Aperture Radar Interferometry (D-InSAR) methodology, they found that while there was little displacement on the UNESCO sites, negative vertical displacement occurred in certain parts of the historical city of Paphos. These maps(i.e. Figure 2) can provide quick and precise information to local authorities, enabling them to preserve the heritage sites to the greatest extent possible.\n\n\n\nFigure 2. Final displacement map at (a) western Cyprus; (b) \"Nea Paphos\"; and (c) \"Tombs of the Kings\"."
  },
  {
    "objectID": "Week4-policy.html#reflection",
    "href": "Week4-policy.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\n\nThrough the class and case study, I have learned that remotely sensed data can be a powerful tool for heritage monitoring and conservation. The combination of satellite and aerial imagery, coupled with machine learning techniques, can provide policymakers with valuable insights into the most effective strategies for heritage conservation, regardless of the natural environment where the heritage sites are located.\nConsidering the reality of London, a significant portion of its heritage sites are buildings located within the city. It is likely that more studies could utilize UAVs, street imagery, or SAR to monitor and preserve these heritage sites in the future. Such studies can provide policymakers with valuable insights into the current condition of the heritage sites and help identify potential risks or threats to their preservation, allowing for effective preservation measures to be implemented.\n\n\n\n\n\n“Historic Environment.” n.d. https://www.cityoflondon.gov.uk/services/planning/cityoflondon.gov.uk/services/planning/historic-environment.\n\n\nOrengo, Hector A., Francesc C. Conesa, Arnau Garcia-Molsosa, Agustín Lobo, Adam S. Green, Marco Madella, and Cameron A. Petrie. 2020. “Automated Detection of Archaeological Mounds Using Machine-Learning Classification of Multisensor and Multitemporal Satellite Data.” Proceedings of the National Academy of Sciences 117 (31): 18240–50. https://doi.org/10.1073/pnas.2005583117.\n\n\nTapete, Deodato, and Francesca Cigna. 2018. “Appraisal of Opportunities and Perspectives for the Systematic Condition Assessment of Heritage Sites with Copernicus Sentinel-2 High-Resolution Multispectral Imagery.” Remote Sensing 10 (4): 561. https://doi.org/10.3390/rs10040561.\n\n\nTzouvaras, Marios, Dimitris Kouhartsiouk, Athos Agapiou, Chris Danezis, and Diofantos G. Hadjimitsis. 2019. “The Use of Sentinel-1 Synthetic Aperture Radar (SAR) Images and Open-Source Software for Cultural Heritage: An Example from Paphos Area in Cyprus for Mapping Landscape Changes After a 5.6 Magnitude Earthquake.” Remote Sensing 11 (15): 1766. https://doi.org/10.3390/rs11151766."
  },
  {
    "objectID": "Week1.html#summary-for-lecture",
    "href": "Week1.html#summary-for-lecture",
    "title": "1  Introduction to Remote Sensing",
    "section": "2.1 Summary for Lecture",
    "text": "2.1 Summary for Lecture\n\n2.1.1 Remote Sensors\nA remote sensor system it the instrument designed to detect and measure physical phenomena or environmental conditions from a distance. Remote sensors could be divided into two types as follow:\n\nPassive sensors systems: receive reflected energy\nActive sensors systems: emit electromagnetic waves, such as SAR\n\n\n\n2.1.2 Electromagnetic waves\nThe electromagnetic waves are used by remote sensors to detect and measure physical phenomena, also the carriers of information.\nThe basic properties of electromagnetic waves include wave length(\\(\\lambda\\)), velocity( \\(c\\), rate of oscillation), frequency(\\(v = 3\\times10^8 m/s\\)). They follow the relationship that \\(\\lambda = c/v\\).\n\n2.1.2.1 Related jargon\nThere are also some jargon about electromagnetic waves we need to know:\n\nElectromagnetic radiation(EMR): waves of an electromagnetic field, travel through space and carry radiant\nradiant energy: energy carried by EMR waves\nradiant flux: energy per unit of time\nshortwave radiation: energy from the sun\nsolar irradiacne: energy or solar power from the sun per unit area per unit time\nexitance/emmittance: energy leaving a surface per unit per unit time\n\n\n\n2.1.2.2 Interactions with Earth\nWhen the electromagnetic waves travel to reach the ground stations or remote sensors, they would be affected by Earth’s atmosphere or surface.Thus, it’s important to know how would the Earth’s surface or atmosphere would change the radiant energy.\n\n2.1.2.2.1 Interactions with Earth’s atmosphere\nSome of the particles or molecules in the air would absorb part of electromagnetic waves, while others would change the direction of electromagnetic waves, and this phenomenon is called atmospheric scattering.\nThere are three types of atmospheric scattering:\n\nRayleigh scattering:\nIt happens when particles are very small compared to the wavelength.\nSmaller wavelengths scatter easier, like blue light would scatter more than red light and yellow light. That’s why we would the sky is blue in the daytime, and the sun is yellow and red when sunset as the sun’s angle changes and the light should travel through more Earth’s atmosphere so that more blue light is scattered out.\nMie scattering:\nIt happens when the particles’ diameters are equal to the wavelength.\nNon selective scattering:\nIt happens when the particles are much larger than the wavelength. For example, the clouds would scatter the visible light of the solar radiation. And that’s the reason why we could see the clouds are white in remote sensing images.\n\n\n\n2.1.2.2.2 Interactions with Earth’s surface\nAfter the solar radiation reached the Earth surface, it would either be absorbed, transmitted or reflected. As for remote sensing, the reflected electromagnetic waves could tell use the characteristics of the Earth’s surface.\nSeveral types of surface interactions: Bidirectional Reflectance Distribution Function (BRDF), Polarization, Fluorensence\n\n\n\n\n2.1.3 Remote Sensing Data\n\n2.1.3.1 Data formats\nMostly remote sensing data is stored in raster, and the file formats usually include GeoTiff and HDF, etc.\n\n\n2.1.3.2 Four resolutions\nRemote sensing data are based on four resolutions\n\nSpatial Resolution: The size of the raster cells.\nSpectral Resolution: The number of bands it records data in.\nThere are several concepts related to spectral resolution:\n\nspectral signatures:\nWe take values for each wavelength across the electromagnetic spectrum to create a spectral signature. Every feature on earth have a unique spectral signature\natmospheric window:\nThe observable wavelengths ranges that are not absorbed by the atmosphere and are transmitted through the atmosphere. Water vapour, ozone, carbon dioxide and atmospheric molecules blocks 100% of the gamma rays, x-rays, and most ultra-violet light.\n\n\n\n\n\n\nRadiometric Resolution: The ability of a sensor to identify and shows small differences.\nTemporal Resolution: The revisit time of the sensor."
  },
  {
    "objectID": "Week3-corrections.html#summary-for-lecture",
    "href": "Week3-corrections.html#summary-for-lecture",
    "title": "3  Corrections",
    "section": "3.2 Summary for Lecture",
    "text": "3.2 Summary for Lecture\n\n3.2.1 Correction\n\n3.2.1.1 Geometric Correction\nCauses: view angle(off-nadir, off directly down), topography, wind, rotation of the earth\nSolutions:\n\nSteps:\n\n\nFind Ground Control Points(GCP) to match known points in the incorrect image and a reference correct dataset.\nThen use a transformation algorithm to model the actual coordinates, like linear regression with distorted x or y as the dependent or independent.\nLater, plot these and minimize the RMSE, whereas the lower RMSE the better model fits.\nLast, resample the final raster because the value of pixels in raster might shift slightly, and the common resample data including Nearest Neighbor, Linear, Cubic and Cubic Spline.\n\n\nTwo Methods:\n\nForward Mapping: Input to output\nThere would be points in the incorrect map falling outside the boundary of the correct map.\nBackward Mapping: Output to input\nThis method completely avoids problems with gaps and overlaps.\n\n\n3.2.1.2 Atmospheric Correction\nCauses: atmospheric scattering and topographic attenuation\nTips: There are both necessary and unnecessary atmospheric corrections. We only need to do the necessary atmospheric corrections.\nSolutions:\n\nTypes:\n\n\nRelative correction: Avoid the evaluation of atmospheric components of any kind(“Living Textbook | Relative Atmospheric Correction | by ITC, University of Twente,” n.d.).\n\nNormalize intensities of different bands within a single image\nNormalize intensities of bands from many dates to one date\nDark object subtraction or histogram adjustment\nPseudo-invariant Features(PIFS)\n\nAbsolute correction:\n\nRequirements: an atmospheric model, local atmospheric visibility and image altitude\nChange digital brightness values into scaled surface reflectance\n\nEmpirical line correction\nSteps:\n\nUsing a filed spectrometer,which require measurements at the same time as the satellite overpass\nThen use this measurements in linear regression against the satellite data raw digital number.\n\n\n\n\n3.2.1.3 Orthorectification Correction\nCauses: a systematic sensor and platform-induced geometry errors, which introduce terrain distortions when the sensor is not pointing directly at the Nadir location of the sensor.\nSolution:\n\nCosine correction\nMinnaert correction\nStatistical Empirical correction\nC Correction (advancing the Cosine)\n\n\n\n3.2.1.4 Radiometric Calibration\nCauses: sensors capture images brightness and distributed as a Digital Number(DN), which allows for efficient storage but has no units.\nSolution:\nDN to spectral radiance\n\n\n\n3.2.2 Data Joining and Enhancement\nData Joining\nMosaicking\n\n3.2.2.1 Image Enhancement\ncontrast enhancement\nratio\nfiltering\npca\ntexture\nfusion"
  },
  {
    "objectID": "Week3-corrections.html#summary-for-practical",
    "href": "Week3-corrections.html#summary-for-practical",
    "title": "3  Corrections",
    "section": "3.3 Summary for Practical",
    "text": "3.3 Summary for Practical"
  },
  {
    "objectID": "Week1.html",
    "href": "Week1.html",
    "title": "1  Introduction to Remote Sensing",
    "section": "",
    "text": "2 Application\nWe have already known that each object on the Earth has their own spectral signature, and it is also real that the same object in different status would have different spectral signatures, like healthy tree would show different colors compared to pest-infested trees. In this way, one important application of spectral indicators is forest monitoring.\nGupta and Pandey (2021) developed a systematic approach using Sentinel-2A spectral images to measure the forest health. The workflow could be seen as below.\nIn terms of data collection and preprocessing, Gupta and Pandey (2021) collected Sentinel 2A data in May and October 2019, and resampled the data into 30m, then performed atmospheric correction. At the same time, they convert the digital numbers of top-of-atmosphere reflectance into bottom-of-atmosphere, which is the true surface reflectance.\nThen, they used reflectance estimation to calculate ARI 1, which shows signs of stressed related to pigments. They applied the Near Infrared(NIR) band to calculating the NDVI so that greenness vegetation are measured. The structure insensitive pigment index were also calculated. These three index were all calculated from spectral bands(see as follows). Canopy chlorophyll content is based on the inversion of PROSAIL.\nFinally, all the four index combined together to calculate the comprehensive Forest Health index. As we can see the figure below, different colors show various health conditions of the forest. The reddest area shows that the forests of this area are in poorest health, while the greenest area’s forests are the healthiest."
  },
  {
    "objectID": "Week1.html#summary-for-practical",
    "href": "Week1.html#summary-for-practical",
    "title": "1  Introduction to Remote Sensing",
    "section": "2.2 Summary for Practical",
    "text": "2.2 Summary for Practical\nData Source:\nSentinel: could be processed either in QGIS or SNAP.\nLandsat:\nRS & R:\npackages: terra, stars, raster"
  },
  {
    "objectID": "Week1.html#questions",
    "href": "Week1.html#questions",
    "title": "1  Introduction to Remote Sensing",
    "section": "2.3 Questions",
    "text": "2.3 Questions"
  },
  {
    "objectID": "Week6-classification1.html#summary",
    "href": "Week6-classification1.html#summary",
    "title": "6  Classification1",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 Classification and Regression Trees (CART)\n\nclassification trees: classifying data into two or more discrete categories\n\nimpure: the mixture of categories among the final leaves\nGini impurity: measure the impurity of a group containing different classes\n\nthe one with the lowest impurity goes at the top of the tree\nuse it at each branch to split the nodes further\n\n\nregression trees: predict continuous dependent variable\n\nresiduals: to decide where the breaks in the data\nsum of the squared residuals(SSR): the one with the lowest SSR is the root of the tree to start with.\n\noverfitting: One leaf with only one pixel value or one person, shows high variance, and does not generalize the model well.\n\nunderfitting: high bias, oversimplifies the model\nsolutions for overfitting:\n\nlimit how trees grow by removing the leaves in each tree\nweakest line pruning with tree score\n\nalpha: gives the lowest SSR form testing data is the final value\n\n\n\n\n6.1.2 Random Forests\n\ngrow many classification decision trees, which comprises the forest\n\ntwo techniques:\n\nbootstrapping(bagging): resampling with replacement. 70% of the training data is used in the bootstrap, 30% is left out of the bag(OOB).\n\nOOB error: proportion of OOB incorrectly classified\n\nrandom feature slection\n\n\n\n\n\n6.1.3 Image Classification\nTurn every pixel in the image into one of a pre-defined categorical classification\n\n6.1.3.1 Unsupervised\n\nDBSCAN: radius and min points\nISODATA: same as k-means but clusters with few pixels are meaningless, close clusters could be merged and could be split for elongated clusters\nCluster Busting: a compensate for the difficulty of assigning meaning in ISODATA\n\n\n\n6.1.3.2 Supervised\n\nparametric\n\nMaximum Likelihood: based on the probability\n\nnon-parametric\n\nSupport Vector Machine (SVM): a linear binary classifier\n\nsupport vectors: points on the boundary\nseparating hyperplane: middle margin\nmaximum margin classifier: maximum margin between two classes\nsoft margin: allow some misclassifications to occur\nunderlying theory: structural risk minimization\nselectable parameters: type of kernel, C (controls the slope), Gamma(controls the distance of influence of a training point)"
  },
  {
    "objectID": "Week6-classification1.html#application",
    "href": "Week6-classification1.html#application",
    "title": "6  Classification1",
    "section": "6.2 Application",
    "text": "6.2 Application\n\n6.2.1 Selection of Classifier\n\nExperiment More\n\nWe have actually learned a lot about classification methods, and have a basic understanding of their theories. However, in practical it’s hard to choose which methods to use when there are so many algorithms available. And there has been few literature generalized a optimum classifier, because the optimum algorithm is usually case-specified depending on the classes mapped, the nature of the training data, and the predictor variables(Maxwell, Warner, and Fang 2018). We should experiment with multiple algorithms to determine which is the optimal for the specific classification task(Lawrence and Moran 2015).\n\nNot just considering Overall Accuracy\n\nIt is also emphasized that the overall accuracy is not just the only thing to consider about, particularly when we are focusing on mapping rare classes. Rare classes would have little impact on the overall accuracy, but would be important in determining the usefulness of classification(Maxwell, Warner, and Fang 2018).\n\n\n6.2.2 What affects the performance of the classification methods?\n\nNumber of training samples and quality of sample data\n\nHuang, Davis, and Townshend (2002) found that the training sample size would have a greater effect on the performance of classification methods especially when using Maximum Likelihood, Decision Tree(DT) and SVM. They further concluded that the size of training sample mainly depend on the algorithm, the number of input variables and the size and spatial variability of mapped area. In broader conclusion by Li et al. (2014), no matter what algorithm would be used, the large and accurate training datasets are more preferable.\nIn terms of data quality, it is not easy to collect a repository of high quality training data due limited time and access. We should select a method that are less sensitive to data quality like mislabeled data samples.\n\nThe balance of classes\n\nThe performance of algorithms would be also affected by the class imbalance. In random sampling, the probability of selecting a class is proportional to the class area, and therefore relatively rare classes will likely comprise a smaller proportion of the training set(Maxwell, Warner, and Fang 2018). In this case, producer’s accuracy and user’s accuracy would become key measures. And they concluded that there are several solutions to balance training data.\n\nuse an equalized stratified random sampling design\nrandomly undersample the majority class, or reduce the overall number of samples used in the training.\nproduce synthetic examples of the minority class that are similar to the original minority examples in the feature space.\nimplement a cost-sensitive method\n\n\nPredefined Parameters\n\nPredefined parameters are also an important impact factor on the performance of classification methods. The default values are usually suggested, but empirical testing to determine the optimum values is still needed to ensure the best performance. Notably, there has been research that avoid using predefined parameters that reduce the influence of user-set parameters(Suel et al. 2019)."
  },
  {
    "objectID": "Week6-classification1.html#reflection",
    "href": "Week6-classification1.html#reflection",
    "title": "6  Classification1",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\n\n\n\n\n\n\n\nHuang, C., L. S. Davis, and J. R. G. Townshend. 2002. “An Assessment of Support Vector Machines for Land Cover Classification.” International Journal of Remote Sensing 23 (4): 725–49. https://doi.org/10.1080/01431160110040323.\n\n\nLawrence, Rick L., and Christopher J. Moran. 2015. “The AmericaView Classification Methods Accuracy Comparison Project: A Rigorous Approach for Model Selection.” Remote Sensing of Environment 170 (December): 115–20. https://doi.org/10.1016/j.rse.2015.09.008.\n\n\nLi, Congcong, Jie Wang, Lei Wang, Luanyun Hu, and Peng Gong. 2014. “Comparison of Classification Algorithms and Training Sample Sizes in Urban Land Classification with Landsat Thematic Mapper Imagery.” Remote Sensing 6 (2): 964–83. https://doi.org/10.3390/rs6020964.\n\n\nMaxwell, Aaron E., Timothy A. Warner, and Fang Fang. 2018. “Implementation of Machine-Learning Classification in Remote Sensing: An Applied Review.” International Journal of Remote Sensing 39 (9): 2784–2817. https://doi.org/10.1080/01431161.2018.1433343.\n\n\nSuel, Esra, John W. Polak, James E. Bennett, and Majid Ezzati. 2019. “Measuring Social, Environmental and Health Inequalities Using Deep Learning and Street Imagery.” Scientific Reports 9 (1): 6229. https://doi.org/10.1038/s41598-019-42036-w."
  },
  {
    "objectID": "Week7-classification2.html#summary",
    "href": "Week7-classification2.html#summary",
    "title": "7  Classification2",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 Object based image analysis (OBIA)\nConsidering shapes based on the similarity(homogeneity) or difference(heterogeneity) of the cells(superpixels)\n\nSimple Linear Iterative Clustering(SLIC): the most common method for superpixel generation\nR packages: Supercells, SegOptim\n\n\n\n7.1.2 Sub pixel analysis\n\nAlso termed: Sub pixel classification, Spectral Mixture Analysis(SMA), Linear Spectral unmixing\nSMA: determines the proportion or abundance of landcover per pixel\n\nAssumption: the reflectance measured at each pixel is represented by the linear sum of endmembers weighted by the associated endmember fraction\n\nconsiderations:\n\npixel purity\nnumber of endmembers\nmultiple endmember spectral analysis\n\n\n\n\n7.1.3 Accuracy assessment\nTP (True Positive): models predicts positive class correctly\nTN (True Negative): models predicts negative class correctly\nFP (False Positive): models predicts positive class incorrectly\nFN (False Negative): models predicts negative class incorrectly\n\nPA (producer’s accuracy)=\\(\\frac{TP}{TP+FN}\\)\nUA (user’s accuracy)=\\(\\frac{TP}{TP+FP}\\)\nOA (the overall accuracy)=\\(\\frac{TP+TN}{TP+FP+FN+TN}\\)\nErrors of omission = 100 - PA\nErrors of commission = 100 - UA\nkappa coefficient: to express the accuracy of an image compared to the results by chance\nF1 score: combines both recall(PA) and precision(UA)\n\nF1 = \\(\\frac{TP+TN}{TP+\\frac12*(FP+FN)}\\),(0,1)\n\nReceiver Operating Characteristic Curve (the ROC Curve): to minimize noise from radar to identify true positives and not miss aircraft\n\nArea Under the ROC Curve(AUC/AUROC): simply the area under the curve, could help us compare models easily.\n\nTrain and Test Split: simply holding back a percentage of the original data used to train the model and then test it at the end.\ncross validation\n\nleave one out cross validation: an extreme version of cross validation\n\nuse all the training data except 1 and repeats though all of it\n\nspatial cross validation\n\nTobler’s first law: the near things are more related than distant things.\nspatially partition the folded data, folds are from cross validation"
  },
  {
    "objectID": "Week7-classification2.html#reflection",
    "href": "Week7-classification2.html#reflection",
    "title": "7  Classification2",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\n\n\n\n\n\n\n\nCampbell, James B., and Randolph H. Wynne. 2011. Introduction to Remote Sensing, Fifth Edition. Guilford Press.\n\n\nFu, Yongyong, Kunkun Liu, Zhangquan Shen, Jinsong Deng, Muye Gan, Xinguo Liu, Dongming Lu, and Ke Wang. 2019. “Mapping Impervious Surfaces in TownRural Transition Belts Using China’s GF-2 Imagery and Object-Based Deep CNNs.” Remote Sensing 11 (3): 280. https://doi.org/10.3390/rs11030280.\n\n\nJovanović, Dušan, Milan Gavrilović, Dubravka Sladić, Aleksandra Radulović, and Miro Govedarica. 2021. “Building Change Detection Method to Support Register of Identified Changes on Buildings.” Remote Sensing 13 (16): 3150. https://doi.org/10.3390/rs13163150.\n\n\nTang, Zixia, Mengmeng Li, and Xiaoqin Wang. 2020. “Mapping Tea Plantations from VHR Images Using OBIA and Convolutional Neural Networks.” Remote Sensing 12 (18): 2935. https://doi.org/10.3390/rs12182935.\n\n\nWang, Lei, Yang Chen, Luliang Tang, Rongshuang Fan, and Yunlong Yao. 2018. “Object-Based Convolutional Neural Networks for Cloud and Snow Detection in High-Resolution Multispectral Imagers.” Water 10 (11): 1666. https://doi.org/10.3390/w10111666.\n\n\nXofis, Panteleimon, and Konstantinos Poirazidis. 2018. “Combining Different Spatio-Temporal Resolution Images to Depict Landscape Dynamics and Guide Wildlife Management.” Biological Conservation 218 (February): 10–17. https://doi.org/10.1016/j.biocon.2017.12.003."
  },
  {
    "objectID": "Week7-classification2.html#application",
    "href": "Week7-classification2.html#application",
    "title": "7  Classification2",
    "section": "7.2 Application",
    "text": "7.2 Application\nPixel based analysis is appropriate for moderate and low resolution, however, as the spatial resolution of satellite images has become finer it makes difficult to classify at the pixel level(Jovanović et al. 2021). It relys on spectral values of individual pixels, is not able to capture the spatial context and variations of different land covers in high-resolution images(Campbell and Wynne 2011). OBIA as an alternative method could bypass the problem of pixel based analysis by by grouping a number of pixels into shapes with a meaningful representation of the objects.\nBesides, OBIA has clear advantages in cooperating multi-source data, such as data obtained from Digital Terrain Maps (DTMs) and other thematic maps. This method also enhances classification tasks, especially in accurately mapping heterogeneous landscapes(Xofis and Poirazidis 2018).\nRecent studies have been combining OBIA and Convolutional Neural Network (CNN), which has been shown to effectively high-level image features, maintain clear boundaries of image objects(Fu et al. 2019; Wang et al. 2018). In the research conducted by Tang, Li, and Wang (2020), they combined OBIA with CNN to form an object-based CNN to extract the tea plantations(sees Figure 1). They revealed that the use of CNN in OBIA setting can effectively improve mapping accuracy, particularly in terms of geometric accuracy.\n\n\n\nFigure 1. The graphical abstract"
  },
  {
    "objectID": "Week8-temperature.html#summary",
    "href": "Week8-temperature.html#summary",
    "title": "8  Temperature",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Urban Heat Island\n\n8.1.1.1 Factors\n\nTwo main factors\n\nmore dark surfaces that retain heat\nless vegetation that cools environment\n\nOther factors\n\nlow Sky View Factor(SVF)\nair speed, cloud cover, cyclic solar radiation, building material type\nsocial factors\nenvironmental \neconomic(local and gdp)\n\n\n\n\n\n8.1.2 Global policy\n\nNew urban agenda\nSustainable Development Goals\nBeat the heat handbook \n\nSuperblock\n\nBackground\nSuperillies-15min city\nFuture: wide scale\n\nGreen corridors\nSydney western hubs\nReflections\n\nUseful project ideas but not given specifics\n\n\n\n\n\n8.1.3 Metropolitan UHI reduction activities\n\nvoluntary\npolicy\n\nMetropolitan strategies \nLocal city mandate\nExapmles: Fremantles’s urban forest plan\n\nPlanning requirements:\n\nPerth\nSingapore: location is ignored just say you have to have it"
  },
  {
    "objectID": "Week8-temperature.html#application",
    "href": "Week8-temperature.html#application",
    "title": "8  Temperature",
    "section": "8.2 Application",
    "text": "8.2 Application\nIn my perspective, the construction of a superblock in Barcelona appears to bring more benefits than harm. By restricting the use of cars within the superblock, there is a decrease in harmful emissions, which can improve air quality(Nieuwenhuijsen and Khreis 2016). Additionally, the inclusion of more green spaces can help reduce the urban heat island effect while also enhancing the visual appeal of the community. The design of the superblock encourages individuals to cross the streets on foot, promoting increased physical activity. This pedestrian-friendly environment can also boost local businesses, as people are more likely to stop and explore street-side shops.\nBesides, I am interested in learning how to evaluate whether a city block has the potential to become a superblock.\nIn the article proposed by Eggimann (2022), they firstly identified possible superblock locations, whose geometric properties resemble Barcelona’s superblocks. Then they collected street information, building information and land use for the assessment of potential superblock implementation in different levels (see as Figure 1).\n\n\n\nFigure 1. Graphical overview of the methodological workflow\n\n\nAs we are concerning remote sensing application, so I would ignore the details of street and building information. They need the current state of the urban green space to derive potential opportunities for converting grey (or non-green) space. They therefore used a canopy height model developed by Christian Ginzler (2021) to identify everything classified asurban green with a height above 5 cm.\n\nThe canopy height model, also known as the Vegetation Height Model, has been developed specifically for Switzerland. To create this model, stereo images provided by the Swiss authorities were utilized to generate a digital surface model (DSM). The DSM was subsequently normalized using a Digital Terrain Model (DTM) that was based on laser data with buildings masked out. This allowed for the accurate calculation of vegetation heights.\n\nThis study for assessing the potential of blocks being converted to superblocks has the transferability to apply to other cities using corresponding datasets. However, it’s important to note that this study only considered the opportunities of converting urban green spaces. In the future, more comprehensive evaluations that consider the interplay between public transportation, and walkability will be necessary."
  },
  {
    "objectID": "Week8-temperature.html#reflection",
    "href": "Week8-temperature.html#reflection",
    "title": "8  Temperature",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\n\nTransferability could be applied to any other cities\n\n\n\n\n\nChristian Ginzler. 2021. “Vegetation Height Model NFI.” https://doi.org/10.16904/1000001.1.\n\n\nEggimann, Sven. 2022. “Expanding Urban Green Space with Superblocks.” Land Use Policy 117 (June): 106111. https://doi.org/10.1016/j.landusepol.2022.106111.\n\n\nNieuwenhuijsen, Mark J., and Haneen Khreis. 2016. “Car Free Cities: Pathway to Healthy Urban Living.” Environment International 94 (September): 251–62. https://doi.org/10.1016/j.envint.2016.05.032."
  },
  {
    "objectID": "Week3-corrections.html",
    "href": "Week3-corrections.html",
    "title": "3  Corrections",
    "section": "",
    "text": "4 : mostly used to describe radiometrically and geometrically consistent data that include cloud and other poor-quality observation flags for filtering data prior to analysis(Dwyer et al. 2018)\nHowever, when the ARD dataset was still not common to us all, we still needed to do corrections with remote sensing images. Otherwise, there would be significant impacts on our research. And below are the applications and operations of corrections in research.\nIn Hadjimitsis et al. (2010)’s work, to evaluate the impacts of atmospheric correction on the agricultural application(detailly, the calculation of vegetation indices), they finished the geometric correction, radiometric correction at Yeroskipou area in Paphos district (the south-west area of Cyprus).\nFirstly, the images were geometrically corrected and geo-referenced to the World Geodetic System’84 (WGS 84/UTM) projection system using a suitable number of identifiable ground control points. Then they used a second order polynomial transformation and kept the RMSE smaller than 1 pixel.\nAs for radiometric correction, as usual, they converted Digital Numbers(DN) to units of radiance by using standard calibration values. Then, the darkest pixel atmospheric correction method (also termed as histogram minimum method) was applied. To calibrate the at-satellite radiance values in each spectral band for the study area, a dark target (e.g. a water dam) was carefully chosen. The average radiance value of the dark target was then subtracted from each at-satellite radiance value in every spectral band.\nFinally, they tested the impact of atmospheric effects on (a) the calculation of vegetation indices; (b) comparison between at-satellite reﬂectance and spectro-radiometric values; and (c) the calculation of real daily evapotranspiration.\nTen Landsat TM/ETM+ images were utilized to assess the impact of atmospheric correction on the accuracy of vegetation indices and evapotranspiration estimates. The results indicate that atmospheric effects must be taken into account for the calculation of DVI, NDVI, SAVI, and MSAVI indices.\nEven the availability of ARD improve efficieny for research, some processing is still necessary. It is stated that the variability in data availability across space and time, along with partial incompleteness caused by clouds, acquisition orbits, and observation scenarios, necessitates the use of specialized algorithms or an additional round of processing. This is required to generate spatial completeness and temporal equidistance, ensuring that the data is ready for analysis(Frantz 2019). Therefore, it is cruicial to have highly analysis ready data(hARD) and hARD+, see as figure below"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "CASA0023-LearningDiary",
    "section": "About Me",
    "text": "About Me\nPrevious Education: BSc in Geographical Information Science, Wuhan University, Wuhan, China"
  }
]